{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpS6YicAqNtO"
      },
      "outputs": [],
      "source": [
        "#STart with example data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EDxjLZ1Oqb_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#data cleaning\n",
        "# The following code performs data cleaning on the dataset All_patients_summary_fact_table_de_id. First, it selects relevant features needed for model building. Then, it filters out patients with missing or zero age and those with unspecified or other genders. Finally, it filters the dataset to include only races that are well represented.#\n",
        "\n",
        "\n",
        "def data_cleaning(All_patients_summary_fact_table_de_id):\n",
        "    # Select features for model bulding\n",
        "    df = All_patients_summary_fact_table_de_id.select(\"age\",\"BMI_max_observed_or_calculated\",\"sex\",\"race\",\"race_ethnicity\",\"OBESITY_indicator\",\"PREGNANCY_indicator\",\"TOBACCOSMOKER_indicator\",\"CARDIOMYOPATHIES_indicator\",\"CEREBROVASCULARDISEASE_indicator\",\"CHRONICLUNGDISEASE_indicator\",\"CONGESTIVEHEARTFAILURE_indicator\",\"CORONARYARTERYDISEASE_indicator\",\n",
        "\"DEMENTIA_indicator\",\"DEPRESSION_indicator\",\"DIABETESCOMPLICATED_indicator\",\"DIABETESUNCOMPLICATED_indicator\",\"DOWNSYNDROME_indicator\",\"HEARTFAILURE_indicator\",\"HEMIPLEGIAORPARAPLEGIA_indicator\",\"HIVINFECTION_indicator\",\"HYPERTENSION_indicator\",\"KIDNEYDISEASE_indicator\",\"MALIGNANTCANCER_indicator\",\"METASTATICSOLIDTUMORCANCERS_indicator\",\"MILDLIVERDISEASE_indicator\",\"MODERATESEVERELIVERDISEASE_indicator\",\"MYOCARDIALINFARCTION_indicator\",\"OTHERIMMUNOCOMPROMISED_indicator\",\"PEPTICULCER_indicator\",\"PERIPHERALVASCULARDISEASE_indicator\",\"PSYCHOSIS_indicator\",\"PULMONARYEMBOLISM_indicator\",\"RHEUMATOLOGICDISEASE_indicator\",\"SICKLECELLDISEASE_indicator\",\"SUBSTANCEUSEDISORDER_indicator\",\"THALASSEMIA_indicator\",\"TUBERCULOSIS_indicator\",\"SYSTEMICCORTICOSTEROIDS_indicator\",\"patient_death_indicator\")\n",
        "\n",
        "    # Select patients age if it is null or zero dropped it\n",
        "    df_age = df.where(df.age>=1)\n",
        "    print ('# of patients age>1 between dates are', df_age.count())\n",
        "\n",
        "    # Dropped Sex if it is missing or others (No matching concepts)\n",
        "    df_gender = df_age.where((df_age.sex == 'MALE') | (df_age.sex == 'FEMALE'))\n",
        "    print ('# of patients with gender Male or Female', df_gender.count())\n",
        "\n",
        "    # Select race with good representation in the data\n",
        "    df_race = df_gender.where((df_gender.race == 'White') | (df_gender.race == 'Asian') |(df_gender.race == 'Black or African American') | (df_gender.race == 'Unknown'))\n",
        "    print ('# of patients with race (white, Asian,Black and Unknown', df_race.count())\n",
        "\n",
        "    return df_race\n",
        "\n"
      ],
      "metadata": {
        "id": "KDy2hEBKqcUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#FEature enginerring\n",
        "\n",
        "### ðŸ§ª Feature Engineering for Group Comparison\n",
        "\n",
        "# This node prepares the dataset for downstream analysis by selecting relevant clinical and demographic features, then creating binary group indicators to compare model behavior across populations.\n",
        "\n",
        "# Specifically, it:\n",
        "# - Selects key variables (e.g., age, comorbidities, outcomes).\n",
        "# - Converts race and sex into simplified group indicators for demonstration: `1` for individuals identified as White or male (privileged), and `0` otherwise.\n",
        "# - Converts the resulting Spark DataFrame into a Pandas DataFrame for use in fairness evaluation and visualization steps later in the pipeline.\n",
        "\n",
        "# This setup allows us to explore how model predictions may vary across groups, using a basic and replicable example for teaching purposes.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import IntegerType\n",
        "\n",
        "# Initialize Spark session\n",
        "spark = SparkSession.builder.appName(\"FeatureEngineering\").getOrCreate()\n",
        "\n",
        "def feature_engineering_privilege(data_cleaning):\n",
        "\n",
        "    # Select relevant columns\n",
        "    df = data_cleaning.select(\n",
        "        \"age\", \"sex\", \"race\", \"OBESITY_indicator\", \"PREGNANCY_indicator\", \"TOBACCOSMOKER_indicator\",\n",
        "        \"CARDIOMYOPATHIES_indicator\", \"CEREBROVASCULARDISEASE_indicator\", \"CHRONICLUNGDISEASE_indicator\",\n",
        "        \"CONGESTIVEHEARTFAILURE_indicator\", \"CORONARYARTERYDISEASE_indicator\", \"DEMENTIA_indicator\",\n",
        "        \"DEPRESSION_indicator\", \"DIABETESCOMPLICATED_indicator\", \"DIABETESUNCOMPLICATED_indicator\",\n",
        "        \"DOWNSYNDROME_indicator\", \"HEARTFAILURE_indicator\", \"HEMIPLEGIAORPARAPLEGIA_indicator\",\n",
        "        \"HIVINFECTION_indicator\", \"HYPERTENSION_indicator\", \"KIDNEYDISEASE_indicator\",\n",
        "        \"MALIGNANTCANCER_indicator\", \"METASTATICSOLIDTUMORCANCERS_indicator\", \"MILDLIVERDISEASE_indicator\",\n",
        "        \"MODERATESEVERELIVERDISEASE_indicator\", \"MYOCARDIALINFARCTION_indicator\",\n",
        "        \"OTHERIMMUNOCOMPROMISED_indicator\", \"PEPTICULCER_indicator\", \"PERIPHERALVASCULARDISEASE_indicator\",\n",
        "        \"PSYCHOSIS_indicator\", \"PULMONARYEMBOLISM_indicator\", \"RHEUMATOLOGICDISEASE_indicator\",\n",
        "        \"SICKLECELLDISEASE_indicator\", \"SUBSTANCEUSEDISORDER_indicator\", \"THALASSEMIA_indicator\",\n",
        "        \"TUBERCULOSIS_indicator\", \"SYSTEMICCORTICOSTEROIDS_indicator\", \"patient_death_indicator\",\n",
        "\n",
        "    )\n",
        "\n",
        "    # Define a dictionary of values to replace in Race\n",
        "    replace_dict = {'Black or African American': 'Black_or_African_American'}\n",
        "    df = df.replace(replace_dict, subset=['race'])\n",
        "\n",
        "    # Convert race and sex to privileged and unprivileged groups\n",
        "    df = df.withColumn(\"sex_privilege\", F.when(F.col(\"sex\") == \"MALE\", 1).otherwise(0))\n",
        "    df = df.withColumn(\"race_privilege\", F.when(F.col(\"race\") == \"White\", 1).otherwise(0))\n",
        "\n",
        "    # Select the necessary columns and convert to Pandas DataFrame\n",
        "    df = df.select([col for col in df.columns if col not in [\"sex\", \"race\"]]).toPandas()\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "wkRg82xbqcWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#feature scaling\n",
        "#The following code performs feature scaling and removes quasi-constant features from the dataset. It first separates the continuous features and applies standard scaling to ensure they #are on a comparable scale. Then, it concatenates the scaled continuous features back with the categorical features. Finally, it removes quasi-constant features, which have 99% of their #values the same, to ensure the dataset is suitable for model building.\n",
        "\n",
        "\n",
        "def feature_scaling(feature_engineering_privilege):\n",
        "    df = feature_engineering_privilege\n",
        "    # continous feature\n",
        "    continous_features = [\"age\"]\n",
        "    df_cont = df[continous_features]\n",
        "\n",
        "    # Create a StandardScaler object\n",
        "    scaler = StandardScaler()\n",
        "    continous_features_ss = pd.DataFrame(scaler.fit_transform(df_cont), columns = df_cont.columns.tolist())\n",
        "\n",
        "    # drop continous features from dataframe to select cotegorical features\n",
        "    columns = df_cont.columns.tolist()\n",
        "    df_cate = df.drop(columns, axis = 1)\n",
        "\n",
        "    # categorical_features = df_cate.columns.tolist()\n",
        "    df_scaled = pd.concat([continous_features_ss , df_cate], axis = 1 )\n",
        "\n",
        "    # remove constant features  (since summary table shows that there is no constant features)\n",
        "#    constant_filter = VarianceThreshold(threshold = 0)\n",
        "#    constant_filter.fit(df)\n",
        "#    df = df[df.columns[constant_filter.get_support(indices = True)]]\n",
        "\n",
        "    # Remove quasi_constant features ( here we exclude feature which have 99% same values in the features)\n",
        "    quasi_constant_filter = VarianceThreshold(threshold = 0.01)\n",
        "    quasi_constant_filter.fit(df_scaled)\n",
        "    df_scaled = df_scaled[df_scaled.columns[quasi_constant_filter.get_support(indices = True)]]\n",
        "\n",
        "    return df_scaled\n",
        ""
      ],
      "metadata": {
        "id": "KahkA_OhqcZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predict\n",
        "\n",
        "# Train a logistic regression model to predict chronic lung disease.\n",
        "# The target is 'CHRONICLUNGDISEASE_indicator'. We split the dataset,\n",
        "# fit the model, generate predictions, and evaluate performance using\n",
        "# a confusion matrix and classification report.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def predict_lung(feature_scaling):\n",
        "    # Convert to Pandas DataFrame if necessary\n",
        "    if isinstance(feature_scaling, pd.DataFrame):\n",
        "        df = feature_scaling\n",
        "    else:\n",
        "        df = feature_scaling.toPandas()\n",
        "\n",
        "    # Define features and target\n",
        "    y = df['CHRONICLUNGDISEASE_indicator']\n",
        "    X = df.drop(['CHRONICLUNGDISEASE_indicator'], axis=1)\n",
        "    # print(y)\n",
        "    # print('-----------------------------------------------------')\n",
        "    # print(X)\n",
        "    # Split the data into training and testing sets\n",
        "    train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train the logistic regression model\n",
        "    logreg = LogisticRegression(max_iter=1000)\n",
        "    logreg.fit(train_x, train_y)\n",
        "\n",
        "    # Predict total_visits on the test set\n",
        "    test_y_pred = logreg.predict(test_x)\n",
        "\n",
        "    # Print the confusion matrix and classification report\n",
        "    cm = confusion_matrix(test_y, test_y_pred)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(test_y, test_y_pred))\n",
        "\n",
        "    # Add predictions to the original dataframe for the entire dataset\n",
        "    df['predicted_CHRONICLUNGDISEASE_indicator'] = logreg.predict(X)\n",
        "\n",
        "\n",
        "\n",
        "    return df\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "xhkp8Wa0qtlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Race fairness\n",
        "\n",
        "# This function calculates accuracy, TPR, FPR, FNR, and PPP for each group\n",
        "# defined by the `race_privilege` indicator (1 = White, 0 = Non-White).\n",
        "# It then computes the ratio of unprivileged to privileged group metrics\n",
        "# to observe any large performance gaps. This step helps identify whether\n",
        "# the model behaves consistently across these two race-based groups.\n",
        "\n",
        "# Output: Group-Level Performance Ratios (Non-White / White)\n",
        "# This output shows how the model's performance compares across race-defined groups.\n",
        "# A TPR ratio > 1 means the unprivileged group had a higher true positive rate.\n",
        "# Similar interpretations apply for FPR, FNR, accuracy, and PPP.\n",
        "# Large differences across these ratios suggest inconsistent model behavior across groups.\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "def calculate_race_fairness_metrics(predict_lung):\n",
        "\n",
        "    # Calculate fairness for a subgroup of population\n",
        "    def fairness_metrics(df):\n",
        "        cm = confusion_matrix(df['y'], df['y_pred'])\n",
        "        TN, FP, FN, TP = cm.ravel()\n",
        "\n",
        "        N = TP + FP + FN + TN  # Total population\n",
        "        ACC = (TP + TN) / N  # Accuracy\n",
        "        TPR = TP / (TP + FN)  # True positive rate\n",
        "        FPR = FP / (FP + TN)  # False positive rate\n",
        "        FNR = FN / (TP + FN)  # False negative rate\n",
        "        PPP = (TP + FP) / N  # % portion of predicted as positive\n",
        "\n",
        "        return np.array([ACC, TPR, FPR, FNR, PPP])\n",
        "\n",
        "    predict_lung['y'] = predict_lung['CHRONICLUNGDISEASE_indicator']\n",
        "    predict_lung['y_pred'] = predict_lung['predicted_CHRONICLUNGDISEASE_indicator']\n",
        "\n",
        "    # Calculate fairness metrics for race\n",
        "    fm_race_1 = fairness_metrics(predict_lung[predict_lung['race_privilege'] == 1])\n",
        "    fm_race_0 = fairness_metrics(predict_lung[predict_lung['race_privilege'] == 0])\n",
        "    fm_race = fm_race_0 / fm_race_1\n",
        "\n",
        "    print(\"Fairness metrics for race (Non-White/White):\")\n",
        "    print(f\"Accuracy Ratio: {fm_race[0]:.4f}\")\n",
        "    print(f\"TPR Ratio: {fm_race[1]:.4f}\")\n",
        "    print(f\"FPR Ratio: {fm_race[2]:.4f}\")\n",
        "    print(f\"FNR Ratio: {fm_race[3]:.4f}\")\n",
        "    print(f\"PPP Ratio: {fm_race[4]:.4f}\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "BOtkPNTCqtoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#intersectional fairness matrix\n",
        "\n",
        "# This function calculates key performance metrics (accuracy, TPR, FPR, FNR, PPP)\n",
        "# for groups defined by race, sex, and their intersection (e.g., Female & Non-White).\n",
        "# Ratios are calculated to compare group-level differences.\n",
        "# This helps assess whether the model behaves consistently across combined group identities.\n",
        "\n",
        "# Output: Group Performance Metrics\n",
        "# The model performs very differently across subgroups.\n",
        "# - TPR and PPP ratios are particularly high for Non-White and Female groups,suggesting over-prediction or more positive classifications.\n",
        "# - Intersectional metrics show that some subgroups (e.g., Female & White, Male & Non-White) receive almost no positive predictions, with a TPR near 0 and FNR near 1.\n",
        "# These results highlight that even if overall accuracy looks acceptable,\n",
        "# model behavior may be highly inconsistent across intersectional identities.\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "def calculate_intersectional_fairness_metrics_1(predict_lung):\n",
        "\n",
        "    # Calculate fairness for a subgroup of population\n",
        "    def fairness_metrics(df):\n",
        "        cm = confusion_matrix(df['y'], df['y_pred'])\n",
        "        TN, FP, FN, TP = cm.ravel()\n",
        "\n",
        "        N = TP + FP + FN + TN  # Total population\n",
        "        ACC = (TP + TN) / N  # Accuracy\n",
        "        TPR = TP / (TP + FN)  # True positive rate\n",
        "        FPR = FP / (FP + TN)  # False positive rate\n",
        "        FNR = FN / (TP + FN)  # False negative rate\n",
        "        PPP = (TP + FP) / N  # % predicted as positive\n",
        "\n",
        "        return np.array([ACC, TPR, FPR, FNR, PPP])\n",
        "\n",
        "    predict_lung['y'] = predict_lung['CHRONICLUNGDISEASE_indicator']\n",
        "    predict_lung['y_pred'] = predict_lung['predicted_CHRONICLUNGDISEASE_indicator']\n",
        "\n",
        "    # Calculate fairness metrics for race\n",
        "    fm_race_1 = fairness_metrics(predict_lung[predict_lung['race_privilege'] == 1])\n",
        "    fm_race_0 = fairness_metrics(predict_lung[predict_lung['race_privilege'] == 0])\n",
        "    fm_race = fm_race_0 / fm_race_1\n",
        "    print(\"Fairness metrics for race (Non-White/White):\")\n",
        "    print(f\"Accuracy Ratio: {fm_race[0]:.4f}, TPR Ratio: {fm_race[1]:.4f}, FPR Ratio: {fm_race[2]:.4f}, FNR Ratio: {fm_race[3]:.4f}, PPP Ratio: {fm_race[4]:.4f}\\n\")\n",
        "\n",
        "    # Calculate fairness metrics for sex\n",
        "    fm_sex_1 = fairness_metrics(predict_lung[predict_lung['sex_privilege'] == 1])\n",
        "    fm_sex_0 = fairness_metrics(predict_lung[predict_lung['sex_privilege'] == 0])\n",
        "    fm_sex = fm_sex_0 / fm_sex_1\n",
        "    print(\"Fairness metrics for sex (Female/Male):\")\n",
        "    print(f\"Accuracy Ratio: {fm_sex[0]:.4f}, TPR Ratio: {fm_sex[1]:.4f}, FPR Ratio: {fm_sex[2]:.4f}, FNR Ratio: {fm_sex[3]:.4f}, PPP Ratio: {fm_sex[4]:.4f}\\n\")\n",
        "\n",
        "    # Calculate fairness metrics for intersection of race and sex\n",
        "    predict_lung['intersection_group'] = predict_lung.apply(\n",
        "        lambda row: f\"{'Male' if row['sex_privilege'] == 1 else 'Female'}_\"\n",
        "                    f\"{'White' if row['race_privilege'] == 1 else 'Non-White'}\", axis=1)\n",
        "\n",
        "    intersection_groups = predict_lung['intersection_group'].unique()\n",
        "    for group in intersection_groups:\n",
        "        subset = predict_lung[predict_lung['intersection_group'] == group]\n",
        "        metrics = fairness_metrics(subset)\n",
        "        print(f\"Fairness metrics for {group.replace('_', ' & ')}:\")\n",
        "        print(f\"Accuracy: {metrics[0]:.4f}, TPR: {metrics[1]:.4f}, FPR: {metrics[2]:.4f}, FNR: {metrics[3]:.4f}, PPP: {metrics[4]:.4f}\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "6JNM4ZrfqtsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Additional Methods for bias mitigation"
      ],
      "metadata": {
        "id": "g7ijMEBwrHwo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#SMOTE\n",
        "\n",
        "\n",
        "# In this step, we use SMOTE (Synthetic Minority Oversampling Technique) to address the class imbalance problem\n",
        "# by generating synthetic examples for the minority class (chronic lung disease cases).\n",
        "# This balances the training data before fitting a logistic regression model.\n",
        "\n",
        "# Output: The confusion matrix and classification report show how the model performs after applying SMOTE:\n",
        "# - Class 1 recall improved dramatically (from 0% to 65%), meaning the model is now catching many more positive cases.\n",
        "# - However, precision for class 1 is still very low, which means the model is also producing many false positives.\n",
        "# - Overall accuracy dropped compared to the imbalanced model, but this is expected since the model is now more focused\n",
        "#   on detecting the minority class instead of only optimizing for the majority.\n",
        "# This trade-off is common when addressing imbalance and highlights the need to look beyond accuracy alone.\n",
        "\n",
        "###########################################################\n",
        "#Note: When applying SMOTE (Synthetic Minority Over-sampling Technique), the standard method does not consider privileged and unprivileged groups during the oversampling process. SMOTE generates synthetic samples for the minority class without accounting for any specific fairness constraints related to these groups.However, there are fairness-aware variants of SMOTE, such as Fair-SMOTE, which aim to balance the representation of privileged and unprivileged groups. These methods specifically ####modify the oversampling process to address fairness issues by ensuring that the generated synthetic samples do not exacerbate existing biases\n",
        "##############################################################\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "def predict_lung_SMOTE(feature_scaling):\n",
        "    # Convert to Pandas DataFrame if necessary\n",
        "    if isinstance(feature_scaling, pd.DataFrame):\n",
        "        df = feature_scaling\n",
        "    else:\n",
        "        df = feature_scaling.toPandas()\n",
        "\n",
        "    # Define features and target\n",
        "    y = df['CHRONICLUNGDISEASE_indicator']\n",
        "    X = df.drop(['CHRONICLUNGDISEASE_indicator'], axis=1)\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Apply SMOTE to the training data\n",
        "    smote = SMOTE(random_state=42)\n",
        "    train_x_resampled, train_y_resampled = smote.fit_resample(train_x, train_y)\n",
        "\n",
        "    # Train the logistic regression model on resampled data\n",
        "    logreg = LogisticRegression(max_iter=1000)\n",
        "    logreg.fit(train_x_resampled, train_y_resampled)\n",
        "\n",
        "    # Predict chronic lung disease on the test set\n",
        "    test_y_pred = logreg.predict(test_x)\n",
        "\n",
        "    # Print the confusion matrix and classification report\n",
        "    cm = confusion_matrix(test_y, test_y_pred)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(test_y, test_y_pred))\n",
        "\n",
        "    # Add predictions to the original dataframe for the entire dataset\n",
        "    df['predicted_CHRONICLUNGDISEASE_indicator'] = logreg.predict(X)\n",
        "\n",
        "    return df\n",
        ""
      ],
      "metadata": {
        "id": "P5x2B5bcrMiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#REWEIGTING\n",
        "\n",
        "# Reweighting with Fairlearn GridSearch (Demographic Parity Constraint)\n",
        "#\n",
        "# In this code, we apply a fairness-aware training method using Fairlearnâ€™s GridSearch.\n",
        "# The goal is to train a logistic regression model that meets a fairness constraint:\n",
        "# specifically, *demographic parity* â€” meaning the model should predict positive outcomes\n",
        "# at similar rates across groups defined by sex and race privilege.\n",
        "#\n",
        "# To achieve this, Fairlearn adjusts the importance (weights) of different training samples\n",
        "# during model training. These weights guide the model to treat each group more equally,\n",
        "# especially when one group is underrepresented or harder to classify.\n",
        "#\n",
        "# Is this Pre-processing or In-processing?\n",
        "# - **Statistically**, reweighting is sometimes introduced as a *pre-processing* technique\n",
        "#   because it adjusts how data contributes to training without modifying the model itself.\n",
        "# - **Practically**, when using Fairlearnâ€™s `GridSearch`, reweighting happens *during*\n",
        "#   model optimization â€” so it functions as an *in-processing* method.\n",
        "#\n",
        "# Output Interpretation:\n",
        "# - The model now identifies more positive cases in the minority class (recall for class 1 is 28%),\n",
        "#   but precision remains low, and overall accuracy dropped to 68%.\n",
        "# - This is a typical trade-off when enforcing fairness constraints: group-level balance improves,\n",
        "#   but performance metrics like precision and accuracy may decline.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from fairlearn.reductions import GridSearch, DemographicParity\n",
        "from fairlearn.metrics import MetricFrame, selection_rate, true_positive_rate, true_negative_rate\n",
        "\n",
        "def predict_lung_with_reweighting(feature_scaling):\n",
        "    # Convert to Pandas DataFrame if necessary\n",
        "    if isinstance(feature_scaling, pd.DataFrame):\n",
        "        df = feature_scaling\n",
        "    else:\n",
        "        df = feature_scaling.toPandas()\n",
        "\n",
        "    # Define features and target\n",
        "    y = df['CHRONICLUNGDISEASE_indicator']\n",
        "    X = df.drop(['CHRONICLUNGDISEASE_indicator'], axis=1)\n",
        "    sensitive_features = df[['sex_privilege', 'race_privilege']]\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    train_x, test_x, train_y, test_y, train_s, test_s = train_test_split(X, y, sensitive_features, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Define logistic regression model\n",
        "    estimator = LogisticRegression(max_iter=1000)\n",
        "\n",
        "    # Apply GridSearch for reweighting\n",
        "    mitigator = GridSearch(estimator, constraints=DemographicParity(), grid_size=10)\n",
        "    mitigator.fit(train_x, train_y, sensitive_features=train_s)\n",
        "\n",
        "    # Predict on the test set\n",
        "    test_y_pred = mitigator.predict(test_x)\n",
        "\n",
        "    # Print the confusion matrix and classification report\n",
        "    cm = confusion_matrix(test_y, test_y_pred)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(test_y, test_y_pred))\n",
        "\n",
        "    # Add predictions to the original dataframe for the entire dataset\n",
        "    df['predicted_CHRONICLUNGDISEASE_indicator'] = mitigator.predict(X)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "VAlBRd1FrMpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adversal nn\n",
        "# Adversarial Debiasing with Neural Networks\n",
        "# This node demonstrates a simple implementation of adversarial debiasing, a fairness-aware machine learning technique that tries to reduce the model's reliance on sensitive attributes (like race) during prediction.\n",
        "\n",
        "# How It Works:\n",
        "# Primary Task:\n",
        "# We first train a neural network to predict whether a patient has chronic lung disease. This is the main prediction task (the \"primary model\").\n",
        "\n",
        "# Adversarial Task:\n",
        "# After the primary model is trained, we use its predicted outputs to train a second model (the \"adversary\") that tries to predict the sensitive attribute â€” in this case, race_privilege.\n",
        "# If the adversary performs well, it suggests that the primary model is leaking information about race â€” even if race wasn't explicitly used in the model input.\n",
        "\n",
        "# Goal:\n",
        "# In a more advanced setup, the two models would be trained jointly so that the primary model learns to make accurate predictions while minimizing the adversaryâ€™s ability to detect group membership. Here, we demonstrate just the core logic for educational purposes.\n",
        "\n",
        "# Outputs:\n",
        "# The confusion matrix and classification report for the primary task show how well the model predicts lung disease.\n",
        "\n",
        "# The adversarial results show how much sensitive group information remains in the model output â€” if performance is high, bias is still present; if it drops, the model may be fairer.\n",
        "\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "def predict_lung_with_adversarial_nn(feature_scaling):\n",
        "    # Convert to Pandas DataFrame if necessary\n",
        "    df = feature_scaling if isinstance(feature_scaling, pd.DataFrame) else feature_scaling.toPandas()\n",
        "\n",
        "    # Define features and target for the primary task\n",
        "    y_primary = df['CHRONICLUNGDISEASE_indicator']\n",
        "    X = df.drop(['CHRONICLUNGDISEASE_indicator', 'race_privilege'], axis=1)\n",
        "\n",
        "    # Split the data into training and testing sets for the primary task\n",
        "    train_x, test_x, train_y, test_y = train_test_split(X, y_primary, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Build the primary model (simplified neural network)\n",
        "    input_layer = Input(shape=(train_x.shape[1],))\n",
        "    dense_layer = Dense(32, activation='relu')(input_layer)\n",
        "    output_layer = Dense(1, activation='sigmoid')(dense_layer)\n",
        "\n",
        "    primary_model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    primary_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the primary model\n",
        "    primary_model.fit(train_x, train_y, epochs=2, batch_size=32, validation_split=0.1, verbose=0)\n",
        "\n",
        "    # Predict on the test set for the primary task\n",
        "    test_y_pred_primary = (primary_model.predict(test_x) > 0.5).astype(\"int32\")\n",
        "\n",
        "    # Print the confusion matrix and classification report for the primary task\n",
        "    cm_primary = confusion_matrix(test_y, test_y_pred_primary)\n",
        "    cr_primary = classification_report(test_y, test_y_pred_primary, target_names=['No Chronic Lung Disease', 'Chronic Lung Disease'])\n",
        "\n",
        "    print(\"Confusion Matrix for Primary Task:\")\n",
        "    print(cm_primary)\n",
        "    print(\"\\nClassification Report for Primary Task:\")\n",
        "    print(cr_primary)\n",
        "\n",
        "    # Add primary task predictions to the original dataframe\n",
        "    df['predicted_CHRONICLUNGDISEASE_indicator'] = (primary_model.predict(X) > 0.5).astype(\"int32\")\n",
        "\n",
        "    # Define features and target for the adversarial task (predicting sensitive attribute 'race_privilege')\n",
        "    y_adversary = df['race_privilege']\n",
        "    X_adversary = df[['predicted_CHRONICLUNGDISEASE_indicator']]  # Using the predictions from the primary task\n",
        "\n",
        "    # Split the data into training and testing sets for the adversarial task\n",
        "    train_x_adv, test_x_adv, train_y_adv, test_y_adv = train_test_split(X_adversary, y_adversary, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Build the adversarial model (simplified neural network)\n",
        "    input_layer_adv = Input(shape=(train_x_adv.shape[1],))\n",
        "    dense_layer_adv = Dense(32, activation='relu')(input_layer_adv)\n",
        "    output_layer_adv = Dense(1, activation='sigmoid')(dense_layer_adv)\n",
        "\n",
        "    adversary_model = Model(inputs=input_layer_adv, outputs=output_layer_adv)\n",
        "    adversary_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the adversarial model\n",
        "    adversary_model.fit(train_x_adv, train_y_adv, epochs=2, batch_size=32, validation_split=0.1, verbose=0)\n",
        "\n",
        "    # Predict on the test set for the adversarial task\n",
        "    test_y_adv_pred = (adversary_model.predict(test_x_adv) > 0.5).astype(\"int32\")\n",
        "\n",
        "    # Print the confusion matrix and classification report for the adversarial task\n",
        "    cm_adv = confusion_matrix(test_y_adv, test_y_adv_pred)\n",
        "    cr_adv = classification_report(test_y_adv, test_y_adv_pred, target_names=['No Race Privilege', 'Race Privilege'])\n",
        "\n",
        "    print(\"Confusion Matrix for Adversarial Task:\")\n",
        "    print(cm_adv)\n",
        "    print(\"\\nClassification Report for Adversarial Task:\")\n",
        "    print(cr_adv)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "waAZV0z6raPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#eqilized odds\n",
        "\n",
        "# Post-Processing with Equalized Odds (Fairlearn)\n",
        "# In this example, we apply a post-processing fairness technique using Fairlearnâ€™s ThresholdOptimizer. The goal is to adjust the prediction thresholds after training a standard logistic regression model, without changing the model itself. This method enforces the equalized odds constraint â€” meaning the true positive and false positive rates should be similar across different groups (e.g., by race).\n",
        "\n",
        "# The process is as follows:\n",
        "\n",
        "# We first train a standard logistic regression model.\n",
        "\n",
        "# Then, we use ThresholdOptimizer to adjust decision thresholds based on group membership (race_privilege) to satisfy the fairness constraint.\n",
        "\n",
        "# We evaluate model performance before and after applying post-processing, and also calculate fairness metrics like demographic parity difference and equalized odds difference.\n",
        "\n",
        "# Note: Post-processing is often more flexible because it doesnâ€™t require altering the original model, making it especially useful in situations where retraining is not feasible.\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from fairlearn.postprocessing import ThresholdOptimizer\n",
        "from fairlearn.metrics import demographic_parity_difference, equalized_odds_difference\n",
        "\n",
        "def apply_equalized_odds(feature_scaling):\n",
        "    df= feature_scaling\n",
        "    # Define features and target\n",
        "    y = df['CHRONICLUNGDISEASE_indicator']\n",
        "    X = df.drop(['CHRONICLUNGDISEASE_indicator'], axis=1)\n",
        "    sensitive_feature = df['race_privilege']\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test, sensitive_train, sensitive_test = train_test_split(X, y, sensitive_feature, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train the logistic regression model\n",
        "    logreg = LogisticRegression(max_iter=1000)\n",
        "    logreg.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred = logreg.predict(X_test)\n",
        "\n",
        "    # Print the confusion matrix and classification report before post-processing\n",
        "    print(\"Confusion Matrix before post-processing:\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    print(\"\\nClassification Report before post-processing:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Apply the Equality of Odds post-processing technique\n",
        "    threshold_optimizer = ThresholdOptimizer(\n",
        "        estimator=logreg,\n",
        "        constraints=\"equalized_odds\",\n",
        "        prefit=True\n",
        "    )\n",
        "    threshold_optimizer.fit(X_train, y_train, sensitive_features=sensitive_train)\n",
        "    y_pred_post = threshold_optimizer.predict(X_test, sensitive_features=sensitive_test)\n",
        "\n",
        "    # Print the confusion matrix and classification report after post-processing\n",
        "    print(\"Confusion Matrix after post-processing:\")\n",
        "    print(confusion_matrix(y_test, y_pred_post))\n",
        "    print(\"\\nClassification Report after post-processing:\")\n",
        "    print(classification_report(y_test, y_pred_post))\n",
        "\n",
        "    # Assess fairness metrics\n",
        "    dem_parity_diff = demographic_parity_difference(y_test, y_pred_post, sensitive_features=sensitive_test)\n",
        "    eq_odds_diff = equalized_odds_difference(y_test, y_pred_post, sensitive_features=sensitive_test)\n",
        "\n",
        "    print(\"Demographic Parity Difference after post-processing:\", dem_parity_diff)\n",
        "    print(\"Equalized Odds Difference after post-processing:\", eq_odds_diff)\n",
        "\n",
        "    # Add predictions to the original dataframe for the entire dataset\n",
        "    df['predicted_CHRONICLUNGDISEASE_indicator'] = logreg.predict(X)\n",
        "    df['post_processed_CHRONICLUNGDISEASE_indicator'] = threshold_optimizer.predict(X, sensitive_features=df['race_privilege'])\n",
        "\n",
        "    return df\n",
        "\n"
      ],
      "metadata": {
        "id": "0tL3JjPhraST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5_yAGC0ZrMsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2igi3Ds4rMvY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}